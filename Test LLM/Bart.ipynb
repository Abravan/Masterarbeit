{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              prompt\n",
      "0  During the Day time, the weather was Clear sky...\n",
      "1  During the Day time, the weather was Overcast ...\n",
      "2  During the Night time, the weather was Partly ...\n",
      "3  During the Night time, the weather was Partly ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'drive data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Combine columns into descriptive prompts\n",
    "def create_prompt(row):\n",
    "    return (f\"During the {row['Day/Night']} time, the weather was {row['Weather Conditions']} \"\n",
    "            f\"with a temperature of {row['Temperature[°C]']}°C, \"\n",
    "            f\"humidity at {row['Humidity[%]']}%, and precipitation of {row['Precipitation[mm]']} mm.\")\n",
    "\n",
    "data['prompt'] = data.apply(create_prompt, axis=1)\n",
    "print(data[['prompt']].head())  # Preview the prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fatem\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\fatem\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\fatem\\.cache\\huggingface\\hub\\models--facebook--bart-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# Load BART model and tokenizer\n",
    "model_name = \"facebook/bart-large\"  # Standard BART model\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fatem\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated descriptions saved to Bart_result.csv\n"
     ]
    }
   ],
   "source": [
    "# Generate text for each prompt\n",
    "generated_texts = []\n",
    "\n",
    "for prompt in data['prompt']:\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    outputs = model.generate(inputs[\"input_ids\"], max_length=100, num_return_sequences=1, temperature=0.7)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    generated_texts.append(generated_text)\n",
    "\n",
    "# Add generated texts back to the DataFrame\n",
    "data['generated_text'] = generated_texts\n",
    "\n",
    "# Save to a new CSV\n",
    "output_path = 'Bart_result.csv'\n",
    "data.to_csv(output_path, index=False)\n",
    "print(f\"Generated descriptions saved to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
